# Google SRE notes
## 1. 介绍
- 目前看来，UNIX系统内部细节和1-3层网络知识时Google最看重的两类额外的技术能力。
- SRE团队必须将50%的精力花在真实的开发工作（工程）上。
- SRE处理运维工作的一项准册时：在每8-12小时的oncall轮值期间最多只处理两个紧急事件。
- 任何产品都不是，也不应该做到100%可靠。
- SRE的目标是根据一个预设的延迟目标部署和维护足够的容量。
## 2. Google生产环境
- Borg下一代， Kubernetes。
- 一个缓慢的不断重启的实例要好过一个永远不重启一直泄露资源的实例。
- Protocol Buffer是Google RPC的传输格式。
## 3. 拥抱风险
- 在Bigtable的例子中，我们可以构建两个集群：低延迟集群和高吞吐量集群。
## 4. 服务质量目标
- 目前Google云计算服务公开的可用性指标是3.5个9， 99.95%可用。
- 响应时间的分布越分散，意味着普通用户受到长尾请求延迟的影响就越明显。
- 长尾效应比算是平均值更有特点。
## 5. 减少琐事
- 琐事就是运维服务中手动性，重复性的，可以被自动化的，战术性，没有持久价值的工作。
- SRE公开50%这个目标是因为如果不加以控制，琐事会变得越来越多，一直是迅速占据我们每个人100%的时间。
## 6. 分布式系统的监控
- Google大量以来白盒监控。
- 监控的4个黄金指标： 延迟，流量，错误和饱和度
- 99%的请求延迟（在某一个小的时间范围内，例如一分钟）可以作为一个饱和度早期预警的指标。
- Google管理团队会按季度进行紧急警报的频率统计（经常以每次oncall轮值发生的故障数量统计，某个故障可能由多个紧急警报组成），保证每个决策者都理解目前的运维压力，以及系统的健康状况。
## 7. Google的自动化系统的演进
- 这些改进有一个连锁效应：节省的时间越多，优化和自动化其他烦琐工作的时间就越多。
- 幂等性（Idempotence)
- 如果关于自动化模块之间的人际互动发生在同一个房间里的人与人之间，集群上线就可以在更短的时间内发生。
- 然后我们又将接下来的几周时间用来进行代码审计，在我们的自动化系统中添加更多的合理性检查，包括速率限制，以及使整个退役流程具有幂等性。
## 8. 发布工程
- Blaze是Google的构建工具，开源版本为[Bazel][1]。
## 9. 简单化
- 有的时候为了灵活性而牺牲稳定性是有意义的。
- 我曾经做过的一些最令人满意的编码工作就是删除了数千行已经没用的代码。
- 在软件工程上，少就是多！一个很小的，很简单的API通常也是一个对问题深刻理解的标志。
- 软件的简单性是可靠性的前提条件。
## 10. 基于时间序列数据进行有效报警
- 这个新模型将收集时间序列信息作为监控系统的首要任务，同时发展了一种丰富的时间序列信息操作语言，通过使用该语言将数据转化为图表和报警取代了以前的探针脚本。
- Google内部产生的每个二进制文件中都默认包含一个HTTP服务。
- 通常情况下，数据中心和全局Borgmon中一般至少需要存放12小时左右的数据量，以便渲染图表使用。
- Time-series monitoring -\> [Prometheus][2], Riemann, Heka和Bosun。
## 11. oncall轮值
- Google有一套非常灵活的报警传递机制，可以将报警信息通过各种不同渠道同时送达多个设备（邮件，短信，自动电话呼叫及APP等）。
- 我们强调至少将团队50%的时间花在软件工程上。其余时间中，不超过25%的时间用来oncall，另外25%的时间用来处理其他运维工作。
- 我们认为，每12个小时的轮值周期最多只能产生两个紧急事件。
- Google提供年假或者现金补贴，同时按一定程度的工资比例作为上限。
- 应该控制SRE团队的大小，保证每个工程师每个季度至少参加oncall一次，最好两次。这样可以保证团队成员有足够的生产环境操作经验。
## 12. 有效的故障排查手段
- 故障报告-定位-检查-诊断-测试／修复-治愈
- 第一反应应该是：尽最大可能让系统恢复服务。
## 13. 紧急事件响应
- 鼓励主动测试
## 14. 紧急事故管理
- ;login:杂志
- Google的紧急事故管理系统是基于[Incident Command System][3]的，这套体系以清晰度和灵活度著称。
- Google发现IRC对紧急事故处理非常有帮助。
- IRC系统非常可靠，同时可以为整个沟通过程提供记录，对处理过程中的细节记录非常有帮助。
- 大部分Google团队使用Google Docs，但是Google Docs团队使用Google Sites做这件事：利用你正要修复的服务来修复该服务恐怕不是什么好主意。
## 15. 事后总结：从失败中学习
- 在任何一个重要事故发生后，团队必须书写一份事后总结。要注意的是，书写事后总结不是一种惩罚措施，而是整个公司的一次学习机会。
- 在SRE的文化中，最重要的就是事后总结“对事不对人”。
- 我们的事后总结文档都是用Google Docs写的，使用一个公司的内部模版。
- 所有的事后总结都需要评审。
## 16. 跟踪故障
- Google使用Outalator-一个故障跟踪工具来做这件事。
- 在Google中，SRE接收的所有报警信息都有一个中央性的，高可用的服务管理。
- SRE当然不仅仅是响应和处理故障。历史数据对响应某个故障来说也很有用。
- Outalator中对一线SRE更有用的功能室可以选择一系列故障，将它们的标题，标签和“重要的”记录信息用邮件格式发给下一个oncall工程师（也可以cc其他人活邮件列表）。
## 17. 测试可靠性
- 测试，是一个用来证明变更前后系统的某些领域相等性的手段。
- 




[1]:	https://bazel.build/
[2]:	https://prometheus.io
[3]:	https://www.fema.gov/national-incident-management-system